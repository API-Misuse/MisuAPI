issues_cnt: 1
issue_0:
  html_url: https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/pull/160
  title: '[revised] .ix to .loc AND [add] .astype() for Type error: reduction operation
    .argmax()'
  body: "First. 'pandas' recommends to change ix to .loc or .iloc.\r\n(https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated)\r\
    \n\r\nhere is for 'label index' so I updated all 'ix' to 'loc'\r\n\r\nSecond,\
    \ Tyep error: reduction operation 'argmax' not allowed for this dtype.\r\n\r\n\
    So I updated it to add .astype('float32') in line 20\r\n\r\n\r\n"
sha: 57ab79dc5762d5b6b7bd50180e7b324a4d47a3ae
message: '[revised] .ix to .loc and [add] .astype for .argmax() typeerror'
commit_log: "commit 57ab79dc5762d5b6b7bd50180e7b324a4d47a3ae\nAuthor: Min Kyung Lee\
  \ <minke7@naver.com>\nDate:   Wed Feb 12 21:32:33 2020 +0900\n\n    [revised] .ix\
  \ to .loc and [add] .astype for .argmax() typeerror"
contained_keywords:
- typeerror
commit_time: 2020-02-12 21:32:33 +0900
commit_author: Min Kyung Lee
added_files: 0
removed_files: 0
modified_files: 1
patched_file_0:
  add_line_no:
  - - 18
    - '

      '
  - - 19
    - '        ## argmax type error

      '
  - - 20
    - '        self.q_table = pd.DataFrame(columns=self.actions).astype(''float32'')

      '
  - - 27
    - '

      '
  - - 28
    - '

      '
  - - 29
    - '            # state_action = self.q_table.ix[observation, :]

      '
  - - 30
    - '            state_action = self.q_table.loc[observation, :]             # for
      label indexing

      '
  - - 33
    - '

      '
  - - 34
    - '

      '
  - - 42
    - '

      '
  - - 43
    - '        q_predict = self.q_table.loc[s, a]

      '
  - - 45
    - '            q_target = r + self.gamma * self.q_table.loc[s_, :].max()  # next
      state is not terminal

      '
  - - 48
    - '        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)  # update

      '
  - - 82
    - '        a = np.random.choice(self.database.loc[s].dropna().index)    # filter
      out the None value

      '
  - - 86
    - '        r, s_ = self.database.loc[s, a]

      '
  added: 15
  del_line_no:
  - - null
    - '        self.q_table = pd.DataFrame(columns=self.actions)

      '
  - - null
    - '            state_action = self.q_table.ix[observation, :]

      '
  - - null
    - '        q_predict = self.q_table.ix[s, a]

      '
  - - null
    - '            q_target = r + self.gamma * self.q_table.ix[s_, :].max()  # next
      state is not terminal

      '
  - - null
    - '        self.q_table.ix[s, a] += self.lr * (q_target - q_predict)  # update

      '
  - - null
    - '        a = np.random.choice(self.database.ix[s].dropna().index)    # filter
      out the None value

      '
  - - null
    - '        r, s_ = self.database.ix[s, a]

      '
  is_added_file: false
  is_binary_file: false
  is_modified_file: true
  is_removed_file: false
  is_rename: false
  path: contents/11_Dyna_Q/RL_brain.py
  removed: 7
  source_file: a/contents/11_Dyna_Q/RL_brain.py
  target_file: b/contents/11_Dyna_Q/RL_brain.py
